{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cffcd95-f61f-4027-9739-1ec66b3631c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from nltk import regexp_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2612ba-0267-410e-b0d5-d4e52524556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "file_dir = current_dir + '\\\\Data\\\\Text_Files'\n",
    "\n",
    "os.chdir(file_dir)\n",
    "text_list = []\n",
    "\n",
    "def read_file(file):\n",
    "    with open(file, 'r', encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text_list.append(text)\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f'{file_dir}\\\\{file}'\n",
    "        read_file(file_path)\n",
    "os.chdir(current_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b253656b-2310-4973-8f8f-a131b116dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data//metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68be0022-84bf-4c6d-980a-bc486b8959ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>President</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Date</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.txt</td>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>['Presidential', 'State of the Union Addresses...</td>\n",
       "      <td>January 06, 1947</td>\n",
       "      <td>Harry S. Truman, Annual Message to the Congres...</td>\n",
       "      <td>Annual Message to the Congress on the State of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.txt</td>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>['Presidential', 'State of the Union Addresses...</td>\n",
       "      <td>January 07, 1948</td>\n",
       "      <td>Harry S. Truman, Annual Message to the Congres...</td>\n",
       "      <td>Annual Message to the Congress on the State of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.txt</td>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>['Presidential', 'State of the Union Addresses...</td>\n",
       "      <td>January 05, 1949</td>\n",
       "      <td>Harry S. Truman, Annual Message to the Congres...</td>\n",
       "      <td>Annual Message to the Congress on the State of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.txt</td>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>['Presidential', 'State of the Union Addresses...</td>\n",
       "      <td>January 04, 1950</td>\n",
       "      <td>Harry S. Truman, Annual Message to the Congres...</td>\n",
       "      <td>Annual Message to the Congress on the State of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.txt</td>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>['Presidential', 'State of the Union Addresses...</td>\n",
       "      <td>January 08, 1951</td>\n",
       "      <td>Harry S. Truman, Annual Message to the Congres...</td>\n",
       "      <td>Annual Message to the Congress on the State of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Text        President                                         Categories  \\\n",
       "0  0.txt  Harry S. Truman  ['Presidential', 'State of the Union Addresses...   \n",
       "1  1.txt  Harry S. Truman  ['Presidential', 'State of the Union Addresses...   \n",
       "2  2.txt  Harry S. Truman  ['Presidential', 'State of the Union Addresses...   \n",
       "3  3.txt  Harry S. Truman  ['Presidential', 'State of the Union Addresses...   \n",
       "4  4.txt  Harry S. Truman  ['Presidential', 'State of the Union Addresses...   \n",
       "\n",
       "               Date                                           Citation  \\\n",
       "0  January 06, 1947  Harry S. Truman, Annual Message to the Congres...   \n",
       "1  January 07, 1948  Harry S. Truman, Annual Message to the Congres...   \n",
       "2  January 05, 1949  Harry S. Truman, Annual Message to the Congres...   \n",
       "3  January 04, 1950  Harry S. Truman, Annual Message to the Congres...   \n",
       "4  January 08, 1951  Harry S. Truman, Annual Message to the Congres...   \n",
       "\n",
       "                                               Title  \n",
       "0  Annual Message to the Congress on the State of...  \n",
       "1  Annual Message to the Congress on the State of...  \n",
       "2  Annual Message to the Congress on the State of...  \n",
       "3  Annual Message to the Congress on the State of...  \n",
       "4  Annual Message to the Congress on the State of...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09838dec-cdfd-4ee3-a7ca-9c8f5b4bf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879ca449-379a-48ab-a80b-e60532fbe187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['Title'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282f32ed-bf2c-4ccc-8c98-5cc12901fe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1947-01-06\n",
       "1    1948-01-07\n",
       "2    1949-01-05\n",
       "3    1950-01-04\n",
       "4    1951-01-08\n",
       "        ...    \n",
       "77   2016-01-12\n",
       "78   2018-01-30\n",
       "79   2019-02-05\n",
       "80   2020-02-04\n",
       "81   2022-03-01\n",
       "Name: Date, Length: 82, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format='%B %d, %Y')\n",
    "df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee391dbb-899d-4847-82db-199160b4818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "president_name = df['President'].tolist()\n",
    "president_text_dict = {keys: [i for _, i in sub] for keys, sub in groupby(\n",
    "         zip(president_name, text_list), key = itemgetter(0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75359f45-ceae-4124-96e3-4e3b9ef537ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Harry S. Truman', 'Dwight D. Eisenhower', 'John F. Kennedy', 'Lyndon B. Johnson', 'Richard Nixon', 'Gerald R. Ford', 'Jimmy Carter', 'Ronald Reagan', 'George Bush', 'William J. Clinton', 'George W. Bush', 'Barack Obama', 'Donald J. Trump', 'Joseph R. Biden'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "president_text_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9427e7-9145-4184-8b90-77b62d834872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(president_text_dict['Barack Obama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ff092b-0dd8-458b-88e9-5d7c8dad74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/36353125/nltk-regular-expression-tokenizer\n",
    "pattern = r'''(?x)          # set flag to allow verbose regexps\n",
    "        (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "      | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "      | \\$?\\d+(?:\\.\\d+)?%?\\s?  # currency and percentages, e.g. $12.40, 82%\n",
    "      | \\.\\.\\.              # ellipsis\n",
    "      | [][.,;\"'?():_`-]    # these are separate tokens; includes ], [\n",
    "    '''\n",
    "\n",
    "pattern = re.compile(pattern)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5361f260-bc04-4dd7-b6bc-ac627eebc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_all(sentence):\n",
    "    l = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(tokenize_text(sentence)):\n",
    "        if tag.startswith('N'):\n",
    "            l.append(wnl.lemmatize(word, pos='n'))\n",
    "        elif tag.startswith('V'):\n",
    "            l.append(wnl.lemmatize(word, pos='v'))\n",
    "        elif tag.startswith('J'):\n",
    "            l.append(wnl.lemmatize(word, pos='a'))\n",
    "        elif tag.startswith('R'):\n",
    "            l.append(wnl.lemmatize(word, pos='r'))\n",
    "            \n",
    "        else:\n",
    "            l.append(wnl.lemmatize(word, pos='n'))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13190e72-5ae3-4427-8fcb-d7c02fe5bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best', 'and', 'write', 'you', 'be']\n"
     ]
    }
   ],
   "source": [
    "sentence_sample = 'The striped bats are  hanging on their feet for best and wrote you are'\n",
    "print(lemmatize_all(sentence_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b4f313-78c8-4477-8079-719ab6e7a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def normalize_and_cleaning(text, remove_punct, lower, stop_word, remove_number, min_len):\n",
    "    \n",
    "    word_tokens = tokenize_text(text)\n",
    "    \n",
    "    if remove_punct:\n",
    "        out =' '.join([word for word in word_tokens if word not in string.punctuation])\n",
    "\n",
    "        \n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    \n",
    "    if remove_number:\n",
    "        my_reg = r'\\$?\\d+\\.?\\d*\\w*\\d*'\n",
    "        text = re.sub(my_reg, '', t)\n",
    "    \n",
    "        \n",
    "    if stop_word:\n",
    "        text = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        \n",
    "    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7952b5c1-daf9-4fc2-80bc-c3185e1fb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That U.S.A. poster-print e.g the U.S costs $12.40  amir hello\n",
      "That U.S.A poster-print e.g the U.S costs 12.40  amir hello\n"
     ]
    }
   ],
   "source": [
    "l = tokenize_text('That U.S.A. poster-print e.g the U.S costs $12.40 amir. hello')\n",
    "t = 'That U.S.A. poster-print e.g the U.S costs $12.40 amir. hello'\n",
    "def punct(text):\n",
    "    text = ' '.join([t for t in tokenize_text(text) if len(t) > 1])\n",
    "    text = ' '.join(word.strip(punctuation) for word in tokenize_text(text))\n",
    "    return text\n",
    "        \n",
    "#punct(t) \n",
    "import re, string\n",
    "\n",
    "def test(text):\n",
    "    out =' '.join([word for word in tokenize_text(text) if word not in string.punctuation])\n",
    "\n",
    "    return out\n",
    "print(test(t))\n",
    "print(punct(t))\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17f4fa1-f1ae-4c39-bb46-b7f8f6c825a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That U.S.A. poster-print e.g the U.S costs amir hello year\n"
     ]
    }
   ],
   "source": [
    "l = 'That U.S.A. poster-print e.g the U.S costs $12.40 3th amir. hello 7. 9 2th 2nd2 5-year $56 $4 1890'\n",
    "\n",
    "def remove_num(t):\n",
    "    my_reg = r'\\$?\\d+\\.?\\d*\\w*\\d*'\n",
    "    text = re.sub(my_reg, '', t)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "y = remove_num(l)\n",
    "print(test(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e46dba9-2eed-4eee-9f1f-bb2376813952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200206d-1c47-418f-af85-daf103cdbe83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
