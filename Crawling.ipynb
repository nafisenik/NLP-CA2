{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f85456-147d-40db-b147-f298dfe898c3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc10902-6294-4f88-9883-db0274e957fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1297f42-db8a-4171-8013-285e15926f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_url_file(url):\n",
    "    urls = []\n",
    "    root_url = \"https://www.presidency.ucsb.edu\"\n",
    "    while True:\n",
    "        req = requests.get(url)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        all_urls = soup.find_all('td',class_='views-field-title')\n",
    "        \n",
    "        for u in all_urls:\n",
    "            link = u.find('a')['href']\n",
    "            urls.append(root_url + link)\n",
    "               \n",
    "        next_page = soup.find('a', {'title': 'Go to next page'})\n",
    "        if next_page:\n",
    "            url = root_url + next_page['href']\n",
    "        else:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "        \n",
    "\n",
    "    f = open('url.txt', 'w')\n",
    "    f.write('\\n'.join(urls))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32bb11f-c734-4adc-bd02-916a1ec27729",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_url_file('https://www.presidency.ucsb.edu/advanced-search?field-keywords=&field-keywords2=&field-keywords3=&from%5Bdate%5D=01-01-1947&to%5Bdate%5D=03-22-2022&person2=&category2%5B%5D=45&category2%5B%5D=400&items_per_page=50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d25679-5c8d-4110-946c-78e500d12c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_data(file):\n",
    "    file1 = open(file , 'r')\n",
    "    urls = file1.readlines()\n",
    "    directory = \"Data/\"\n",
    "    rows=[]\n",
    "    index = 0\n",
    "        \n",
    "    for url in tqdm_notebook(urls):\n",
    "        req = requests.get(url)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        text = soup.find('div', class_= 'field-docs-content').text\n",
    "        president = soup.find(\"h3\", class_='diet-title').text\n",
    "        categories = str([i.text for i in soup.findAll(attrs={\"property\": \"rdfs:label skos:prefLabel\", \"typeof\": \"skos:Concept\"})])\n",
    "        date = soup.find(\"span\", class_= 'date-display-single').text\n",
    "        citation = soup.find(\"p\", class_= 'ucsbapp_citation').text\n",
    "        title = soup.find(\"div\", class_= 'field-ds-doc-title').text.strip()\n",
    "        rows.append([str(index)+\".txt\", president, categories, date, citation, title])\n",
    "        \n",
    "        with open(directory + \"Text_Files/\" + str(index)+\".txt\", 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "            \n",
    "        time.sleep(3)\n",
    "        index+= 1\n",
    "        \n",
    "    fields = ['Text', 'President', 'Categories', 'Date', 'Citation', 'Title']     \n",
    "    with open(directory + 'metadata.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow(fields)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625ad18f-c89b-4b73-9038-21c90335899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nik\\AppData\\Local\\Temp\\ipykernel_14836\\1646720538.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for url in tqdm_notebook(urls):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9998419ee045839262d228b878f2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crawl_data('url.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb7f44-a7f6-4f07-807e-e7625ae523d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
